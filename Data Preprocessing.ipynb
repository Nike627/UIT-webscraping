{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85eea515",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "After viewing the data scraped from The Sun website, some inconsistencies were discovered along with the instruction to only scrape from a particular category. This file contains a script that removes, and correct the inconsistencies and also exclude data from other categories except the selected one which in this case is \"Politics and Power\"\n",
    "\n",
    "This file then goes futher to lowercase, remove punctuations, special characters and extra whitespaces from the data in the \"text\" column and then assign the manipilated data to a new column called \"cleaned_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a96392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5916a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\USER\\UIT-webscraping\\articles_paragraphs.csv\") # loading the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca093d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1) # removing the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3916f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'paragraph': 'text'}) # renaming the column appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446c5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['text'].str.strip().str.match(r'(?i)^(by|from|a)[a-z]')].reset_index(drop=True) # deleting rows that begin with by, from, and a \n",
    "\n",
    "df['text'] = df['text'].str.replace(r'(?i)^(the)([a-z])', r'\\1 \\2', regex=True) # inserting space after \"the\" in rows where it is the first word at the begining of a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd11acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_category = df[df['category'] == 'Politics & Power'].reset_index(drop=True) # selecting paragraphs from a particular paragraph only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f38afb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1bec2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, remove punctuation/special characters and extra whitespaces from the text\n",
    "selected_category['cleaned_text'] = (selected_category['text'].str.lower()\n",
    "                                     .str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "                                     .str.replace(r'\\s+', ' ', regex=True).str.strip())\n",
    "\n",
    "# Remove stop words\n",
    "filtered_texts = []\n",
    "for text in selected_category['cleaned_text']:\n",
    "    words = text.split()               # Split into words\n",
    "    filtered_words = []                # Prepare empty list for filtered words\n",
    "    for word in words:\n",
    "        if word not in stop_words:    # Check if word is NOT a stop word\n",
    "            filtered_words.append(word)  # If not stop word, add to list\n",
    "    cleaned_text = ' '.join(filtered_words)  # Join filtered words back into string\n",
    "    filtered_texts.append(cleaned_text)       # Append cleaned text to list\n",
    "\n",
    "# Assign the cleaned column back\n",
    "selected_category['cleaned_text'] = filtered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7986a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_category.to_csv(r\"C:\\Users\\USER\\UIT-webscraping\\articles_paragraphs_politics.csv\", index=False) # saving the cleaned dataset as a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfd9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
